{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8095f0ce",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering\n",
    "\n",
    "## Introdução\n",
    "\n",
    "O **Hierarchical Clustering** (ou **agrupamento hierárquico**) é um método de *clustering* que busca **construir uma hierarquia de clusters**, em vez de apenas dividir os dados em *K* grupos fixos como o K-Means ou K-Medoids.\n",
    "\n",
    "O resultado é geralmente representado por um **dendrograma**, uma estrutura em árvore que mostra como os clusters são formados (ou divididos) em diferentes níveis de similaridade.\n",
    "\n",
    "---\n",
    "\n",
    "## Tipos de Hierarchical Clustering\n",
    "\n",
    "Existem dois tipos principais de abordagem:\n",
    "\n",
    "1. **Aglomerativo (bottom-up)** — começa com cada ponto como um cluster individual e **vai juntando** os mais próximos até sobrar apenas um cluster.\n",
    "2. **Divisivo (top-down)** — começa com todos os pontos em um único cluster e **vai dividindo** recursivamente em subclusters menores.\n",
    "\n",
    "O método **aglomerativo** é o mais comum e o que normalmente é implementado nas bibliotecas de machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "## Intuição\n",
    "\n",
    "Imagine que cada ponto de dados começa sozinho.  \n",
    "O algoritmo calcula a distância entre todos os pares de pontos e **agrupa os dois mais próximos**.  \n",
    "Depois, recalcula as distâncias entre o novo cluster e os demais, repetindo o processo até formar uma árvore completa de agrupamentos.\n",
    "\n",
    "Essa árvore pode ser cortada em qualquer nível para escolher o número desejado de clusters.\n",
    "\n",
    "---\n",
    "\n",
    "## Etapas do Algoritmo Aglomerativo\n",
    "\n",
    "1. **Inicialização:** cada ponto é considerado um cluster individual.  \n",
    "2. **Cálculo das distâncias:** mede-se a distância entre todos os pares de clusters.  \n",
    "3. **Fusão:** junta-se o par de clusters mais próximos.  \n",
    "4. **Atualização:** recalcula-se as distâncias entre o novo cluster e os demais.  \n",
    "5. **Repetição:** os passos 3 e 4 continuam até restar apenas um cluster contendo todos os pontos.\n",
    "\n",
    "---\n",
    "\n",
    "## Critérios de Ligação (Linkage)\n",
    "\n",
    "A maneira de calcular a distância entre clusters é definida pelo **método de ligação (linkage)**:\n",
    "\n",
    "| Método | Definição | Característica |\n",
    "|--------|------------|----------------|\n",
    "| **Single linkage** | Distância mínima entre pontos de clusters diferentes | Tende a formar clusters longos e encadeados |\n",
    "| **Complete linkage** | Distância máxima entre pontos de clusters diferentes | Cria clusters compactos e pequenos |\n",
    "| **Average linkage** | Média das distâncias entre todos os pares de pontos | Equilíbrio entre os dois anteriores |\n",
    "| **Ward linkage** | Minimiza a variância total dentro dos clusters | Muito usado em dados numéricos (padrão no Scikit-Learn) |\n",
    "\n",
    "---\n",
    "\n",
    "## Representação Matemática\n",
    "\n",
    "Seja \\( C_i \\) e \\( C_j \\) dois clusters e \\( d(x_p, x_q) \\) a distância entre dois pontos:\n",
    "\n",
    "- **Single linkage:**\n",
    "  $$\n",
    "  D(C_i, C_j) = \\min_{x_p \\in C_i, x_q \\in C_j} d(x_p, x_q)\n",
    "  $$\n",
    "\n",
    "- **Complete linkage:**\n",
    "  $$\n",
    "  D(C_i, C_j) = \\max_{x_p \\in C_i, x_q \\in C_j} d(x_p, x_q)\n",
    "  $$\n",
    "\n",
    "- **Average linkage:**\n",
    "  $$\n",
    "  d(C_i, C_j) = \\frac{1}{|C_i| \\cdot |C_j|} \\sum_{x \\in C_i} \\sum_{y \\in C_j} d(x, y)\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d272256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
