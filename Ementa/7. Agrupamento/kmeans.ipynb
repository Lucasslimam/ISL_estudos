{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2b545c",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2125e9a",
   "metadata": {},
   "source": [
    "# K-Means Clustering\n",
    "\n",
    "## Introdução\n",
    "\n",
    "O **K-means** é um algoritmo de *aprendizado não supervisionado* usado para **agrupar dados** em *K* grupos (ou *clusters*) distintos, com base em similaridade.  \n",
    "A ideia principal é simples: queremos dividir o conjunto de dados em *K* grupos de forma que cada ponto pertença ao cluster cujo **centro (centróide)** seja o mais próximo possível.\n",
    "\n",
    "---\n",
    "\n",
    "## Intuição\n",
    "\n",
    "Imagine que você tem vários pontos em um plano (por exemplo, coordenadas de clientes por renda e gasto).  \n",
    "O K-means tentará encontrar **agrupamentos naturais** desses pontos — ou seja, regiões onde os pontos estão mais próximos entre si.\n",
    "\n",
    "Cada grupo é representado por um **centróide**, que é a média dos pontos pertencentes ao cluster.\n",
    "\n",
    "---\n",
    "\n",
    "## Passos do Algoritmo\n",
    "\n",
    "1. **Escolher K** (número de clusters desejados).  \n",
    "2. **Inicializar os centróides** aleatoriamente.  \n",
    "3. **Atribuir cada ponto** ao centróide mais próximo (com base, por exemplo, na distância euclidiana).  \n",
    "4. **Recalcular os centróides** com base na média dos pontos de cada cluster.  \n",
    "5. **Repetir os passos 3 e 4** até que os centróides não mudem mais significativamente (convergência).\n",
    "\n",
    "---\n",
    "\n",
    "## Representação Matemática\n",
    "\n",
    "Seja o conjunto de dados:\n",
    "\n",
    "$$ X = \\{x_1, x_2, \\dots, x_n\\} $$\n",
    "\n",
    "Queremos encontrar os centróides:\n",
    "\n",
    "$$ \\mu_1, \\mu_2, \\dots, \\mu_k $$\n",
    "\n",
    "que minimizem a soma das distâncias quadráticas de cada ponto ao centróide mais próximo:\n",
    "\n",
    "$$\n",
    "J = \\sum_{i=1}^{k} \\sum_{x_j \\in S_i} ||x_j - \\mu_i||^2\n",
    "$$\n",
    "\n",
    "onde:\n",
    "- \\( S_i \\) é o conjunto de pontos pertencentes ao cluster \\( i \\);\n",
    "- \\( ||x_j - \\mu_i||^2 \\) é a distância euclidiana quadrada entre o ponto \\( x_j \\) e o centróide \\( \\mu_i \\).\n",
    "\n",
    "---\n",
    "\n",
    "## Escolha do K\n",
    "\n",
    "O número de clusters **K** é um hiperparâmetro que deve ser definido antes da execução do algoritmo.  \n",
    "Uma técnica comum para escolher **K** é o **Método do Cotovelo (Elbow Method)**:\n",
    "\n",
    "1. Execute o K-means para vários valores de K (por exemplo, 1 a 10);\n",
    "2. Calcule a soma dos erros quadráticos (SSE ou *Inertia*);\n",
    "3. Escolha o valor de K onde a redução do erro começa a diminuir (formando um “cotovelo” no gráfico).\n",
    "\n",
    "---\n",
    "\n",
    "## Exemplo em Python (com Scikit-Learn)\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Gerar dados artificiais\n",
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\n",
    "\n",
    "# Aplicar K-means\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "\n",
    "# Visualizar clusters\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.7)\n",
    "plt.title(\"Clusters formados pelo K-Means\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Pontos Importantes\n",
    "\n",
    "- K-means assume **clusters esféricos** e de tamanhos semelhantes.\n",
    "- É sensível à **inicialização dos centróides** (pode cair em mínimos locais).\n",
    "- A métrica de distância mais usada é a **euclidiana**, mas pode ser adaptada.\n",
    "- Nem sempre é adequado para dados **não numéricos** ou **com escalas muito diferentes** (por isso, recomenda-se padronizar os dados antes).\n",
    "\n",
    "---\n",
    "\n",
    "## Variações do K-Means\n",
    "\n",
    "- **K-Means++:** melhora a escolha inicial dos centróides, acelerando a convergência.  \n",
    "- **MiniBatch K-Means:** versão mais rápida e escalável, usada para grandes volumes de dados.  \n",
    "- **Kernel K-Means:** permite encontrar clusters não lineares, aplicando o truque do kernel.\n",
    "\n",
    "---\n",
    "\n",
    "## Referências\n",
    "\n",
    "- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning.*\n",
    "- Scikit-Learn Documentation: [https://scikit-learn.org/stable/modules/clustering.html#k-means](https://scikit-learn.org/stable/modules/clustering.html#k-means)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
