{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbdfa141",
   "metadata": {},
   "source": [
    "# K-Medoids Clustering\n",
    "\n",
    "## Introdução\n",
    "\n",
    "O **K-Medoids** é um algoritmo de *clustering* semelhante ao **K-Means**, mas com uma diferença fundamental:  \n",
    "em vez de usar a **média (centroide)** para representar um cluster, o K-Medoids usa um **ponto real do conjunto de dados**, chamado **medoide**, como representante do cluster.\n",
    "\n",
    "Isso torna o K-Medoids **mais robusto a outliers** e **mais interpretável**, pois os centróides são pontos reais existentes nos dados.\n",
    "\n",
    "---\n",
    "\n",
    "## Intuição\n",
    "\n",
    "Enquanto o K-Means minimiza a soma das distâncias quadradas aos centróides, o K-Medoids busca minimizar a soma das **distâncias absolutas** entre os pontos e os **medoides**, que são pontos reais do dataset.\n",
    "\n",
    "Em outras palavras:\n",
    "- Cada cluster tem um ponto central (medoide);\n",
    "- Esse medoide é o ponto **mais central** dentro do cluster — o que tem **menor distância média total** aos outros pontos do mesmo grupo.\n",
    "\n",
    "---\n",
    "\n",
    "## Passos do Algoritmo\n",
    "\n",
    "1. **Escolher K**, o número de clusters.  \n",
    "2. **Selecionar aleatoriamente K pontos** do conjunto de dados como medoides iniciais.  \n",
    "3. **Atribuir cada ponto** ao medoide mais próximo (usando uma métrica de distância, como Manhattan ou Euclidiana).  \n",
    "4. **Calcular o custo total** (soma das distâncias entre pontos e seus respectivos medoides).  \n",
    "5. Para cada medoide, **testar a troca** com outros pontos não selecionados:\n",
    "   - Se a troca reduzir o custo total, substituir o medoide pelo novo ponto.\n",
    "6. **Repetir os passos 3–5** até que não haja melhora no custo total (convergência).\n",
    "\n",
    "---\n",
    "\n",
    "## Representação Matemática\n",
    "\n",
    "Dado um conjunto de dados:\n",
    "\n",
    "$$ X = \\{x_1, x_2, ..., x_n\\} $$\n",
    "\n",
    "e um conjunto de medoides:\n",
    "\n",
    "$$ M = \\{m_1, m_2, ..., m_k\\} $$\n",
    "\n",
    "O objetivo é **minimizar o custo total**:\n",
    "\n",
    "$$\n",
    "J = \\sum_{i=1}^{k} \\sum_{x_j \\in S_i} d(x_j, m_i)\n",
    "$$\n",
    "\n",
    "onde:\n",
    "- \\( d(x_j, m_i) \\) é a distância (geralmente Manhattan ou Euclidiana);\n",
    "- \\( S_i \\) é o conjunto de pontos atribuídos ao medoide \\( m_i \\).\n",
    "\n",
    "---\n",
    "\n",
    "## Comparação com K-Means\n",
    "\n",
    "| Característica | K-Means | K-Medoids |\n",
    "|-----------------|----------|------------|\n",
    "| Representante do cluster | Média (ponto teórico) | Medoide (ponto real) |\n",
    "| Sensibilidade a outliers | Alta | Baixa |\n",
    "| Custo computacional | Menor | Maior |\n",
    "| Tipo de distância | Normalmente Euclidiana | Pode ser qualquer métrica |\n",
    "| Escalabilidade | Melhor para grandes dados | Mais caro computacionalmente |\n",
    "\n",
    "---\n",
    "\n",
    "## Algoritmo PAM (Partitioning Around Medoids)\n",
    "\n",
    "O **PAM** (*Partitioning Around Medoids*) é a implementação clássica do K-Medoids.\n",
    "\n",
    "### Etapas:\n",
    "1. Escolhe K pontos iniciais como medoides;\n",
    "2. Atribui cada ponto ao medoide mais próximo;\n",
    "3. Para cada medoide, tenta trocar com um ponto não medoide e calcula o novo custo;\n",
    "4. Mantém a troca se o custo diminuir;\n",
    "5. Repete até a convergência.\n",
    "\n",
    "---\n",
    "\n",
    "## Exemplo em Python (com Scikit-Learn Extra)\n",
    "\n",
    "```python\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gerar dados artificiais\n",
    "X, y = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\n",
    "\n",
    "# Aplicar K-Medoids\n",
    "kmedoids = KMedoids(n_clusters=4, metric='euclidean', random_state=0)\n",
    "kmedoids.fit(X)\n",
    "labels = kmedoids.labels_\n",
    "medoids = kmedoids.cluster_centers_\n",
    "\n",
    "# Visualizar clusters\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', s=50)\n",
    "plt.scatter(medoids[:, 0], medoids[:, 1], c='red', s=200, alpha=0.7, marker='X')\n",
    "plt.title(\"Clusters formados pelo K-Medoids\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "> **Observação:** para usar o `KMedoids`, é necessário instalar o pacote `scikit-learn-extra`:\n",
    "> ```\n",
    "> pip install scikit-learn-extra\n",
    "> ```\n",
    "\n",
    "---\n",
    "\n",
    "## Vantagens e Desvantagens\n",
    "\n",
    "**Vantagens:**\n",
    "- Robusto a outliers;\n",
    "- Pode usar qualquer métrica de distância (não precisa ser Euclidiana);\n",
    "- Medoides são pontos reais — interpretabilidade maior.\n",
    "\n",
    "**Desvantagens:**\n",
    "- Mais lento que K-Means (especialmente com grandes conjuntos de dados);\n",
    "- Requer cálculo de todas as distâncias ponto a ponto (O(n²)).\n",
    "\n",
    "---\n",
    "\n",
    "## Aplicações Comuns\n",
    "\n",
    "- Agrupamento de séries temporais ou dados categóricos (onde médias não fazem sentido);\n",
    "- Segmentação de clientes;\n",
    "- Detecção de anomalias;\n",
    "- Dados com ruído ou outliers.\n",
    "\n",
    "---\n",
    "\n",
    "## Variações Populares\n",
    "\n",
    "- **CLARANS (Clustering Large Applications based upon RANdomized Search):** versão otimizada para grandes conjuntos de dados.\n",
    "- **Fuzzy K-Medoids:** permite que pontos pertençam parcialmente a múltiplos clusters.\n",
    "- **K-Medoids++:** inicialização mais inteligente dos medoides, análogo ao K-Means++.\n",
    "\n",
    "---\n",
    "\n",
    "## Referências\n",
    "\n",
    "- Kaufman, L., & Rousseeuw, P. J. (1990). *Finding Groups in Data: An Introduction to Cluster Analysis.*\n",
    "- Scikit-Learn Extra Documentation: [https://scikit-learn-extra.readthedocs.io/en/latest/generated/sklearn_extra.cluster.KMedoids.html](https://scikit-learn-extra.readthedocs.io/en/latest/generated/sklearn_extra.cluster.KMedoids.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f97af5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2480972232.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_27260\\2480972232.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    O **K-Medoids** é um algoritmo de *clustering* semelhante ao **K-Means**, mas com uma diferença fundamental:\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
