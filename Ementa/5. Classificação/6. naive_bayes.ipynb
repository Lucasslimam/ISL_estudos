{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d98ab7",
   "metadata": {},
   "source": [
    "# 📘 Naive Bayes\n",
    "\n",
    "O **Naive Bayes** é uma família de classificadores probabilísticos baseados no **Teorema de Bayes**, com a suposição “ingênua” (*naive*) de que as variáveis preditoras são **independentes entre si**, dado o rótulo da classe.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧮 Teorema de Bayes\n",
    "\n",
    "O teorema de Bayes descreve a probabilidade de um evento \\( A \\) ocorrer, dado que \\( B \\) ocorreu:\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Em um contexto de classificação, ele é usado para calcular a probabilidade de uma classe \\( C_k \\) dado um vetor de atributos \\( x = (x_1, x_2, ..., x_n) \\):\n",
    "\n",
    "$$\n",
    "P(C_k|x) = \\frac{P(x|C_k) \\cdot P(C_k)}{P(x)}\n",
    "$$\n",
    "\n",
    "Como \\( P(x) \\) é igual para todas as classes, ele pode ser ignorado na decisão final. Assim:\n",
    "\n",
    "$$\n",
    "P(C_k|x) \\propto P(x|C_k) \\cdot P(C_k)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Suposição de Independência\n",
    "\n",
    "O modelo assume que as variáveis $( x_i $) são **condicionalmente independentes** entre si dado \\( C_k \\):\n",
    "\n",
    "$$\n",
    "P(x|C_k) = \\prod_{i=1}^{n} P(x_i | C_k)\n",
    "$$\n",
    "\n",
    "Essa simplificação torna o cálculo muito mais eficiente, mesmo que a independência raramente seja verdadeira na prática.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Tipos de Naive Bayes\n",
    "\n",
    "Existem diferentes variantes do algoritmo, dependendo da distribuição dos dados:\n",
    "\n",
    "1. **Gaussian Naive Bayes (`GaussianNB`)**  \n",
    "   - Usado quando as features são contínuas e seguem uma **distribuição normal**.\n",
    "\n",
    "2. **Multinomial Naive Bayes (`MultinomialNB`)**  \n",
    "   - Usado para **contagens discretas**, como frequência de palavras em documentos (comum em NLP).\n",
    "\n",
    "3. **Bernoulli Naive Bayes (`BernoulliNB`)**  \n",
    "   - Usado para **dados binários** (ex.: presença ou ausência de uma palavra).\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Fórmulas Específicas\n",
    "\n",
    "### 1. Gaussian Naive Bayes\n",
    "\n",
    "Para cada atributo contínuo \\( x_i \\), assume-se uma distribuição normal:\n",
    "\n",
    "$$\n",
    "P(x_i | C_k) = \\frac{1}{\\sqrt{2\\pi\\sigma_k^2}} \\exp\\left(-\\frac{(x_i - \\mu_k)^2}{2\\sigma_k^2}\\right)\n",
    "$$\n",
    "\n",
    "onde $\\mu_k$ e $\\sigma_k$ são a média e o desvio padrão do atributo $x_i$ na classe $C_k$.\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 Vantagens\n",
    "\n",
    "- Extremamente rápido e eficiente, mesmo com muitos atributos.\n",
    "- Funciona bem com **dados textuais** e **alta dimensionalidade**.\n",
    "- Requer **poucos dados de treino**.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ Desvantagens\n",
    "\n",
    "- A suposição de **independência entre atributos** raramente é verdadeira.\n",
    "- Pode ter **baixa performance** quando as features são fortemente correlacionadas.\n",
    "- As probabilidades resultantes podem ser **mal calibradas**.\n",
    "\n",
    "---\n",
    "\n",
    "## 💬 Exemplo de Aplicação\n",
    "\n",
    "- Classificação de e-mails como *spam* ou *não spam*  \n",
    "- Análise de sentimento em textos  \n",
    "- Diagnóstico médico (probabilístico)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21389709",
   "metadata": {},
   "source": [
    "### 🧠 1. **Gaussian Naive Bayes (`GaussianNB`)**\n",
    "\n",
    "#### 📍 Quando usar:\n",
    "- Quando as **features são contínuas** (valores reais) e **aproximadamente seguem uma distribuição normal (gaussiana)**.  \n",
    "- Usado em problemas em que as variáveis são medidas numéricas e independentes (ou quase).\n",
    "\n",
    "#### 💼 Exemplos reais:\n",
    "- **Diagnóstico médico probabilístico**, onde cada atributo representa um exame (ex.: pressão, nível de glicose, colesterol).  \n",
    "- **Reconhecimento de dígitos (MNIST)**, quando as intensidades dos pixels são tratadas como variáveis contínuas.  \n",
    "- **Detecção de fraudes** com variáveis contínuas como valores monetários e tempos de transação.\n",
    "\n",
    "#### 💬 Dica:\n",
    "Mesmo que os dados **não sejam perfeitamente gaussianos**, o modelo ainda tende a funcionar bem — ele é robusto à violação leve da suposição de normalidade.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔢 2. **Multinomial Naive Bayes (`MultinomialNB`)**\n",
    "\n",
    "#### 📍 Quando usar:\n",
    "- Quando as features representam **contagens inteiras não negativas**, especialmente em **dados textuais**.  \n",
    "- Usado em casos onde o valor de cada variável é uma **frequência** (como o número de vezes que uma palavra aparece).\n",
    "\n",
    "#### 💼 Exemplos reais:\n",
    "- **Classificação de e-mails (spam / não spam)** com contagem de palavras (Bag of Words).\n",
    "- **Análise de sentimento** (positivo/negativo) em textos.\n",
    "- **Classificação de documentos** por tema (ex.: esportes, política, tecnologia).\n",
    "\n",
    "#### 💬 Dica:\n",
    "O `MultinomialNB` é o **mais usado em NLP (Processamento de Linguagem Natural)**, e costuma servir como *baseline* em pipelines de texto — simples, rápido e eficaz.\n",
    "\n",
    "---\n",
    "\n",
    "### ⚫ 3. **Bernoulli Naive Bayes (`BernoulliNB`)**\n",
    "\n",
    "#### 📍 Quando usar:\n",
    "- Quando as features são **binárias (0 ou 1)** — indicando presença ou ausência de uma característica.  \n",
    "- Ideal para dados de texto **binarizados** (por exemplo, se uma palavra aparece ou não, sem contar frequência).\n",
    "\n",
    "#### 💼 Exemplos reais:\n",
    "- **Filtragem de spam** baseada na presença de certas palavras.  \n",
    "- **Classificação de textos curtos** (ex.: tweets, títulos de notícias) onde a contagem de palavras é menos informativa.  \n",
    "- **Análise de características booleanas**, como se um usuário realizou ou não determinada ação.\n",
    "\n",
    "#### 💬 Dica:\n",
    "O BernoulliNB é útil quando a **presença** de uma feature importa mais que sua **quantidade**.  \n",
    "Exemplo: “se o texto contém a palavra *‘promoção’*, é um spam — não importa quantas vezes”.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 Comparativo rápido\n",
    "\n",
    "| Tipo | Tipo de dado | Exemplo típico | Vantagem |\n",
    "|------|---------------|----------------|-----------|\n",
    "| **GaussianNB** | Contínuo | Exames médicos, sensores, imagem | Simples, rápido, lida bem com dados reais |\n",
    "| **MultinomialNB** | Contagens (inteiros) | Textos, NLP, classificação de documentos | Muito eficaz e rápido em texto |\n",
    "| **BernoulliNB** | Binário (0/1) | Presença/ausência de palavras | Ideal para dados booleanos |\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ Dica prática: escolha assim\n",
    "\n",
    "- 📄 **Texto:** `MultinomialNB`  \n",
    "- ⚙️ **Atributos binários:** `BernoulliNB`  \n",
    "- 📈 **Atributos contínuos:** `GaussianNB`  \n",
    "- 🧪 **Dataset pequeno e ruídoso:** Naive Bayes costuma se sair bem devido à simplicidade do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e838b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lucas\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 1.0\n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Carregar dataset de exemplo\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 2. Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Criar e treinar o modelo\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# 4. Fazer previsões\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# 5. Avaliar desempenho\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68889c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
