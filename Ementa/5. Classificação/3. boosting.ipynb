{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b2370e",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "Assim como os aprendizados anteriores, são geradas diversas árvores. A diferença é que essa técnica não envolve reamostrar diversas vezes\n",
    "com Bootstrap, ao invés disso, as árvores são geradas sequencialmente por meio de versões modificadas do dataset original.\n",
    "O método de *boosting* aprende *devagar*. Dado um modelo atual, é tentado fittar uma árvore aos resíduos do modelo.\n",
    "\n",
    "## Algoritmo de Boosting\n",
    "1. Defina $\\hat{f}(x) = 0$ e $r_i = y_i$ **para todo $i$** nos dados de treino.\n",
    "2. Para cada $b = 1, 2, \\ldots, B$, repita:\n",
    "\n",
    "    a. Treine uma árvore $\\hat{f}^b$ com $d$ splits (d+1 nós terminais) aos dados de treino $(X, r)$\n",
    "\n",
    "    b. Atualize $\\hat{f}$ adicionando uma versão $shrunk$ da nova árvore:\n",
    "    $$\\hat{f}(x) \\larr \\hat{f}(x) + \\lambda \\hat{f}^b (x)$$\n",
    "\n",
    "    c. Atualize os resíduos\n",
    "    $$r_i \\larr r_i - \\lambda \\hat{f}^b (x_i)$$\n",
    "\n",
    "3. Modelo com *boost*:\n",
    "$$hat{f}(x) = \\sum_{b=1}^{B} \\lambda \\hat{f}^b (x)$$\n",
    "\n",
    "## Parâmetros utilizados\n",
    "1. Número de árvores $B$. Diferentemente de random forests, pode ocorrer overfit se $B$ for muito grande,\n",
    "     geralmente utilizam **validação cruzada para definir $B$**\n",
    "\n",
    "2. O parâmetro de shrink $\\lambda$, que é um pequeno número positivo. Ele controla a velocidade com que o *boosting* aprende.\n",
    "Geralmente são valores 0.01 ou 0.001. Pequenos valores de $\\lambda$ podem demandar um valor maior de $B$\n",
    " para ter uma boa performance.\n",
    "\n",
    "3. Número $d$ de *splits* em cada árvore, que controla a complexididade da árvore final. Geralmente $d=1$ funciona bem e se chama *stump*."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
