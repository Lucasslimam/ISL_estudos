{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "468fe155",
   "metadata": {},
   "source": [
    "# Inteligência Artificial Generativa\n",
    "\n",
    "## 1. Conceitos Fundamentais de IA Generativa\n",
    "\n",
    "A **IA Generativa** é uma área da inteligência artificial focada em **criar novos conteúdos** (texto, imagem, áudio, vídeo, código etc.) que **imitam padrões aprendidos** a partir de dados existentes.\n",
    "\n",
    "### Características principais:\n",
    "- Baseia-se em **modelos probabilísticos** que aprendem a distribuição dos dados.  \n",
    "- Capaz de **gerar amostras novas** e realistas.  \n",
    "- Modelos populares incluem:\n",
    "  - **GANs (Generative Adversarial Networks)**\n",
    "  - **VAEs (Variational Autoencoders)**\n",
    "  - **Transformers (como GPT, BERT, T5, etc.)**\n",
    "\n",
    "### Aplicações:\n",
    "- Geração de texto (ChatGPT, Bard)\n",
    "- Síntese de imagens (DALL·E, Stable Diffusion)\n",
    "- Criação de música e voz sintética\n",
    "- Simulações em pesquisa científica\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Conceitos Fundamentais de NLP (Processamento de Linguagem Natural)\n",
    "\n",
    "O **NLP (Natural Language Processing)** é a área da IA voltada para permitir que máquinas **compreendam, interpretem e gerem linguagem humana**.\n",
    "\n",
    "### Tarefas clássicas:\n",
    "- **Tokenização**: dividir texto em palavras ou subpalavras.  \n",
    "- **Lematização e stemming**: reduzir palavras à sua forma base.  \n",
    "- **POS Tagging**: identificar classes gramaticais.  \n",
    "- **Named Entity Recognition (NER)**: detectar nomes de pessoas, lugares, organizações.  \n",
    "- **Tradução automática, sumarização e geração de texto.**\n",
    "\n",
    "O NLP moderno é dominado por **modelos baseados em Transformers**, que superaram RNNs e LSTMs.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Arquitetura Transformer\n",
    "\n",
    "A arquitetura **Transformer** (Vaswani et al., 2017) revolucionou o NLP e a IA generativa.\n",
    "\n",
    "### Ideia central:\n",
    "Em vez de processar tokens sequencialmente (como RNNs), o Transformer usa **atenção** para processar todos os tokens **em paralelo**, capturando dependências longas com eficiência.\n",
    "\n",
    "### Componentes principais:\n",
    "\n",
    "- **Self-Attention**: mede a importância relativa entre tokens.  \n",
    "  $$\n",
    "  \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
    "  $$\n",
    "\n",
    "- **Multi-Head Attention**: múltiplas “cabeças” aprendem diferentes relações contextuais.  \n",
    "- **Feedforward Networks**: camadas não lineares aplicadas após atenção.  \n",
    "- **Positional Encoding**: adiciona informações de ordem à sequência.  \n",
    "\n",
    "Transformers são a base de modelos como **GPT**, **BERT**, **T5**, **LLaMA**, entre outros.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. In-Context Learning\n",
    "\n",
    "O **In-Context Learning (ICL)** é a capacidade de um modelo **aprender novas tarefas apenas a partir do contexto do prompt**, sem ajustar seus pesos.\n",
    "\n",
    "### Exemplo:\n",
    "\n",
    "Traduza para inglês:\n",
    "\"Olá\" → \"Hello\"\n",
    "\"Bom dia\" → ?\n",
    "\n",
    "O modelo infere o padrão e completa com \"Good morning\" — sem reentreinamento.\n",
    "\n",
    "Isso é possível porque modelos grandes armazenam padrões gerais durante o treinamento, e o prompt fornece **instruções implícitas**.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. RAGs e Bancos de Dados Vetoriais\n",
    "\n",
    "**RAG (Retrieval-Augmented Generation)** combina **busca** e **geração de texto**.\n",
    "\n",
    "### Etapas:\n",
    "1. O prompt do usuário é convertido em um **vetor de embeddings**.  \n",
    "2. Esse vetor é comparado a uma **base vetorial** (ex: FAISS, Pinecone, Weaviate) para buscar os documentos mais relevantes.  \n",
    "3. Esses documentos são **injetados no contexto** do modelo generativo para enriquecer a resposta.\n",
    "\n",
    "### Benefícios:\n",
    "- Permite **respostas atualizadas e contextuais**.  \n",
    "- Reduz **alucinações** de LLMs.  \n",
    "- Não exige reentreinamento do modelo base.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Técnicas de Engenharia de Prompt\n",
    "\n",
    "A **Prompt Engineering** é a arte de **formular instruções** de forma a extrair melhores respostas de um LLM.\n",
    "\n",
    "### Tipos de técnicas:\n",
    "- **Zero-shot**: apenas a instrução direta.  \n",
    "- **Few-shot**: exemplos de entrada e saída no prompt.  \n",
    "- **Chain-of-Thought (CoT)**: instruir o modelo a \"pensar passo a passo\".  \n",
    "- **Role prompting**: atribuir papéis ao modelo (\"Você é um professor de física...\").  \n",
    "- **Self-consistency**: gerar múltiplas respostas e escolher a mais coerente.  \n",
    "\n",
    "---\n",
    "\n",
    "## 7. Técnicas de Treinamento e Fine-Tuning\n",
    "\n",
    "Modelos generativos são treinados em grandes corpora de texto para prever o próximo token:\n",
    "\n",
    "$$\n",
    "\\max_\\theta \\sum_{(x,y)} \\log P_\\theta(y|x)\n",
    "$$\n",
    "\n",
    "### Fases:\n",
    "- **Pré-treinamento**: aprendizado genérico de linguagem.  \n",
    "- **Fine-tuning**: especialização em tarefas específicas.  \n",
    "  - Pode ser **supervisionado** (com pares entrada–saída).  \n",
    "  - Ou **instruído** (Instruction tuning), com prompts e respostas humanas.  \n",
    "\n",
    "Outras abordagens incluem:\n",
    "- **Adapter tuning**: pequenas camadas ajustáveis inseridas no modelo.  \n",
    "- **LoRA (Low-Rank Adaptation)**: atualiza apenas decomposições de matrizes.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Quantization\n",
    "\n",
    "A **quantização** reduz o tamanho e o custo computacional de modelos.\n",
    "\n",
    "### Conceito:\n",
    "Reduz a precisão numérica dos pesos (por exemplo, de 32 bits → 8 bits), mantendo desempenho próximo do original.\n",
    "\n",
    "### Benefícios:\n",
    "- Menor uso de memória.  \n",
    "- Inferência mais rápida.  \n",
    "- Ideal para dispositivos com hardware limitado.\n",
    "\n",
    "Exemplos: **8-bit quantization**, **4-bit quantization**, **mixed precision**.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Embeddings\n",
    "\n",
    "Um **embedding** é uma representação vetorial densa de um elemento (palavra, sentença, imagem, etc.) em um espaço contínuo.\n",
    "\n",
    "### Intuição:\n",
    "Palavras ou objetos com significados semelhantes têm **vetores próximos** no espaço de embeddings.\n",
    "\n",
    "### Propriedades:\n",
    "- Calculados por modelos como **Word2Vec**, **BERT**, ou **SentenceTransformers**.  \n",
    "- Usados em RAGs, busca semântica, e clustering de textos.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. RLHF (Reinforcement Learning from Human Feedback)\n",
    "\n",
    "O **RLHF** é o processo que ensina modelos a **seguir preferências humanas**.\n",
    "\n",
    "### Etapas:\n",
    "1. **Fine-tuning supervisionado**: o modelo aprende com exemplos de respostas humanas.  \n",
    "2. **Treino de um modelo de recompensa**: humanos avaliam respostas → modelo aprende o que é “melhor”.  \n",
    "3. **Treino via PPO (Proximal Policy Optimization)**:\n",
    "   O modelo é ajustado para **maximizar a recompensa** prevista, equilibrando aprendizado e estabilidade.\n",
    "\n",
    "RLHF é usado em modelos como o ChatGPT para tornar as respostas **mais seguras e úteis**.\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Safeguards e Guardrails\n",
    "\n",
    "**Safeguards** e **guardrails** são mecanismos que **limitam comportamentos indesejados** em modelos generativos.\n",
    "\n",
    "### Estratégias:\n",
    "- **Filtragem de prompts e saídas** (detecção de linguagem ofensiva, sensível, etc.)  \n",
    "- **Classificadores de segurança** para evitar instruções perigosas.  \n",
    "- **Red teaming**: testar o modelo contra tentativas de exploração.  \n",
    "- **Content moderation** e **políticas éticas** integradas.  \n",
    "\n",
    "Essas técnicas garantem que os modelos sejam **seguros, éticos e alinhados aos valores humanos**.\n",
    "\n",
    "---\n",
    "\n",
    "## Resumo Visual (estrutura conceitual)\n",
    "\n",
    "\n",
    "## Resumo Estrutural dos Conceitos de IA Generativa\n",
    "\n",
    "IA Generativa\n",
    "|\n",
    "├── NLP (Processamento de Linguagem Natural)\n",
    "|     ├── Tokenização\n",
    "|     ├── Lematização\n",
    "|     ├── Modelos baseados em Transformers\n",
    "|     └── Representações semânticas (embeddings)\n",
    "|\n",
    "├── Modelos Generativos\n",
    "|     ├── GPT / BERT / T5 / LLaMA\n",
    "|     ├── Treinamento e Fine-tuning\n",
    "|     |     ├── Supervisionado\n",
    "|     |     ├── Instruction tuning\n",
    "|     |     └── RLHF (Reinforcement Learning from Human Feedback)\n",
    "|     ├── Quantization (redução de precisão dos pesos)\n",
    "|     └── In-Context Learning (aprendizado via prompt)\n",
    "|\n",
    "├── RAG (Retrieval-Augmented Generation)\n",
    "|     ├── Conversão do prompt em embeddings\n",
    "|     ├── Busca em banco de dados vetorial\n",
    "|     ├── Recuperação dos documentos relevantes\n",
    "|     └── Geração aumentada de respostas\n",
    "|\n",
    "├── Engenharia de Prompt\n",
    "|     ├── Zero-shot\n",
    "|     ├── Few-shot\n",
    "|     ├── Chain-of-Thought\n",
    "|     ├── Role prompting\n",
    "|     └── Self-consistency\n",
    "|\n",
    "└── Segurança e Controle\n",
    "      ├── Guardrails (regras de comportamento)\n",
    "      ├── Safeguards (mecanismos de proteção)\n",
    "      ├── Classificadores de segurança\n",
    "      └── Moderação de conteúdo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
